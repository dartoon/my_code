\documentclass[twocolumn]{aastex62}

\newcommand{\vdag}{(v)^\dagger}
\newcommand\aastex{AAS\TeX}
\newcommand\latex{La\TeX}
\newcommand\s{$\sim$}
\newcommand{\e}{\'{e}}
\newcommand{\amen}[1]{\textbf{\textit{#1}}}

\usepackage{amsmath}
\usepackage{xcolor}
\usepackage{mathrsfs}

\usepackage{float}
\usepackage{multirow}
\usepackage{enumitem} 

\shorttitle{Black hole mass function and its redshift evolution by ET}
\shortauthors{Ding et al.}

\newcommand{\kai}[1]{\textcolor{red}{[{\bf Kai}: #1]}} 

\begin{document}

\newcommand{\mbh}{$\mathcal M_{\rm BH}$}
\newcommand{\cmass}{${\cal M}_0$}
\newcommand{\dl}{$d_L$}
\newcommand{\mone}{$m_1$}
\newcommand{\mtwo}{$m_2$}
\newcommand{\snr}{$\rho$}

\title{Black hole mass function and its evolution -- the first prediction for the Einstein Telescope}

\correspondingauthor{Xuheng Ding}
\email{dingxh@whu.edu.cn}

\author%[0000-0001-8917-2148]
{Xuheng Ding}
\affiliation{School of Physics and Technology, Wuhan University, Wuhan 430072, China}
\affiliation{Department of Physics and Astronomy, University of California, Los Angeles, CA, 90095-1547, USA}

%\author{Lilan Yang}
%\affiliation{School of Physics and Technology, Wuhan University, Wuhan 430072, China}
%\affiliation{Department of Physics and Astronomy, University of California, Los Angeles, CA, 90095-1547, USA}

\author%[0000-0002-4359-5994]
{Kai Liao}
\affiliation{School of Science, Wuhan University of Technology, Wuhan 430070, China}

\author%[0000-0003-1308-7304]
{Marek Biesiada}
\affiliation{Department of Astronomy, Beijing Normal University, Beijing 100875, China}
%\affiliation{Department of Astrophysics and Cosmology, Institute of Physics, University of Silesia, 75 Pu{\l}ku Piechoty 1, 41-500 Chorz{\'o}w,
%Poland}
\affiliation{National Centre for Nuclear Research, Pasteura 7, 02-093 Warsaw, Poland}

\author%[0000-0002-3567-6743]
{Zong-Hong Zhu}
\affiliation{School of Physics and Technology, Wuhan University, Wuhan 430072, China}
\affiliation{Department of Astronomy, Beijing Normal University, Beijing 100875, China}


\begin{abstract}

We demonstrate the ability of future third generation gravitational wave (GW) detector -- the Einstein Telescope (ET) to infer the slope of the BH\kai{black hole} mass function (BHMF) and its evolution with redshift. 
We perform the Monte Carlo simulation of the measurements of binary BH (BBH) systems chirp signals\kai{chirp signals from binary BH systems} that could be detected by ET, including the BH masses and their luminosity distances (\dl). Following the previous works, we consider the mass of a primary black hole in each binary system and model the BHMF as a power-law function with slope parameter $\alpha$. We take into account the bias introdused by the uncertainty of the measurements and by the selection effect. We find that a thousand of GW events registered by ET ($\sim1\%$ amount of its yearly detection rate) could measure the $\alpha$ with $3\%$ accuracy\kai{precision}. Furthermore, we investigate a scenario, that\kai{where}  $\alpha$ is evolving\kai{evolves} with redshift as $\alpha(z) = \alpha_0 + \alpha_1\frac{z}{1+z}$. Our result is that\kai{shows}, taking the\kai{remove ``the"} \dl\ as \kai{the} redshift estimator, with a thousand\kai{one thousand} GW events one is able to obtain an unbiased\kai{since your results are based on mock data/simulation, you can't say ``unbiased"} $\alpha_1$ at the uncertainty level of $\pm0.5$. The ability of gain\kai{gaining} knowledge about the evolution of BHMF would help to understand the origin of the BHs and how BH binaries formed at different stages of the history of the Universe.
\end{abstract}

%\keywords{keywords TBD}

\section{Introduction} \label{sec_intro}
%As first identified as a solution to Einstein's field equations by Schwarzschild in 1916 \citep{Schwarzschild1999}, black holes (BHs) have been predicted to remain a bunches of fundamental questions in unifying GR with quantum physics \citep{Hawking1976, Giddings2017}. 

The masses of astrophysical black holes (BHs) are known to cover a wide range from stellar-mass to supermassive BHs\kai{remove ``BHs"?} $\sim10^{10} M_{\odot}$. Recent discovery of 
coalescing binary black holes (BBHs) in LIGO gravitational-wave (GW) detectors is a substantial evidence of stellar-mass BHs \citep{Abbott2016}, while supermassive BHs are supposed to exist in the centers of almost all the galaxies \citep{Lynden-Bell1969, Kormendy1995}. Quite recently, the first image of a supermassive BH in the center of the giant elliptical galaxy M87 has been reconstructed from radio observations performed by the Event Horizon Telescope \citep{Alberdi2019}. 
GWs provide a direct way to study the inspiralling BBH systems, enabling one to derive their basic parameters including mass, spin and luminosity distance\kai{+s}~\citep{Abbott2017phy}. This creates the opportunity not only to measure the properties of BHs ~\citep{Abbott2018b}, but also answer some fundamental questions concerning cosmography~\citep{Liao2017, Ding2019, Cai2017}, the GW speed~\citep{Fan2017, Collett2017} or the strong lensing of GWs ~\citep{Ola2013, Biesiada2014, Ding2015}. \kai{seems the references are almost related with lensing. I suggest to cite more LIGO references}

Nevertheless, it is still unclear of how the BHs are formed \citep{Fryer1999, Fryer2001, Mirabel2016}. In particular, the number and mass distribution of stellar-mass BHs in the Universe still needs\kai{need} to be clarified.
The recent GW detections have brought us to\kai{remove ``to"} a new era of gravitational wave astronomy \citep[e.g.,][]{Abbott2016, Abbott2016_sum, Abbott2018} and opened up a  brand new possibility in respect of studying BBH systems\kai{system} formation channels. 
At present, however, observations cannot firmly distinguish between basic formation scenarios like the evolution of isolated pairs of stars, dynamic binary
formation in dense clusters and pairs of primordial BHs\kai{add references here}.
Current GWTC-1 catalog of binary coalescences detected by LIGO/Virgo GW interferometers includes 10 BH-BH binaries and one NS-NS (GW170817) binary \citep{Abbott2018}. In the next decade, the number of detected coalescences of BHBH systems is expected to be increasing rapidly with the improvements in\kai{of} the detector sensitivities. 

Focusing on the BH mass function (BHMF) parametrized as a two-sided truncated power-law, \citet{Kovetz2017PhRvD} estimated that further LIGO measurements providing thousands of BBHs would constrain the BHMF slope parameter $\alpha$ at 10\% accuracy. More recently, the LIGO collaboration has used ten BBH merger events and constrained the BHMF power law index to $\alpha~=~1.6\substack{+1.5\\-1.7}$ (90\% credibility) \citep{Abbott2018b}. 
In this study, we use the Monte Carlo (MC) approach to simulate the GW events from BBH systems that could be measured by third-generation gravitational wave detector, the Einstein Telescope (ET) \citep{Abernathy2011}. We construct a mock BBHs\kai{BBH} catalog with the realistic dataset\kai{Since you generate mock data, why do you say ``realistic"?} to examine their ability to constrain the BHMFs, taking into account the data noise level and selection bias in a more realistic way. Moreover, since the ET would detect the GW events from the distant Universe up to $z\sim17$ \citep{Abernathy2011}, the wide redshift range of the BBH events enable us to examine whether it would be possible to detect the $\alpha$ as a function of redshift.

This paper is organized as follows. In Section~\ref{sec_simulation} we describe the simulation of the BBH events detectable by ET using the Monte Carlo approach. In this section, we assume the initial assumptions for the BH mass function used further as true values to be recovered from the data. In Section~\ref{sec_theory}, we introduce the theoretical framework to reconstruct the BHMFs, considering the noise realization and the selection effects. Furthermore, we make a further step by considering the power law index $\alpha$ as a function of redshift and explore the way to use luminosity distance as redshift estimator and detect such evolution. We present our results in the Section~\ref{sec_result}. The discussion and conclusions are given in the last Section~\ref{sec_summary}. \kai{remove ``5" or ``last"}
Throughout this paper, we assume a standard concordance cosmology with $H_0= 70$ km s$^{-1}$ Mpc$^{-1}$, $\Omega{_m} = 0.30$, and $\Omega{_\Lambda} = 0.70$.



\vspace{1cm}
\section{Data simulation} \label{sec_simulation}
In this section we describe the simulation of a realistic mock catalog of GW signals from BBHs detectable by future \textbf{ET interferometric detector}. Numerical predictions of BBH inspirals detecable\kai{detectable} by the\kai{remove ``the"} ET 
have been discussed in many works, and it has been forecasted that the yearly detection rate of BBHs would be of order $\sim10^{4-5}$ \citep{Abernathy2011, Ola2013, Biesiada2014}. More recently, \citet{Yang2019} developed the approach of a Monte Carlo (MC) simulation to predict the detection rate by explicitly considering each BBH inspiral event sampled from the outcome of the population synthesis model, which provides the way to mimic a realistic BBH GW catalog. The backbone of this approach is to build up a mock universe which includes a sufficient volume of BBH events to represent the overall sample. We refer the reader\kai{s} for the details in \citet[][Section 2, therein]{Yang2019}  and briefly recall the key points below.

\subsection{Detection Criteria} \label{subsec_criteria}
We randomly generated the key parameters to determine the signal-to-noise ratio $\rho$ of each GW system. For a specific BBH inspiral event at redshift $z_s$, the ET's corresponding reaction is defined as \citep{Abernathy2011}:

\begin{equation} \label{SNR}
\rho = 8 \Theta \frac{r_0}{d_L(z_s)} \left( \frac{(1+z){\cal M}_0}{1.2 M_{\odot}} \right)^{5/6}
\sqrt {\zeta(f_{max})},
\end{equation}
where $r_0$ is the detector's characteristic distance parameter and $\zeta(f_{max})$ is the dimensionless function reflecting the overlap between the GW signal and the ET's effective bandwidth which is usually simplified as unity. ${\cal M}_0$ is the intrinsic chirp mass defined as $ {\cal M}_0 = \frac{(m_1m_2)^{3/5}}{(m_1+m_2)^{1/5}}$, where \mone\ and \mtwo\ are the
respective masses of the BBH components. $\Theta$ is the orientation factor determined by four angles as \citep{Finn93}:
 \begin{equation} \label{Theta}
 \Theta = 2 [ F_{+}^2(1 + \cos^2{\iota} )^2 + 4 F_{\times}^2 \cos^2{\iota} ]^{1/2},
 \end{equation}
where: $F_{+} = \frac{1}{2} (1 + \cos^2{\theta}) \cos{2\phi} \cos{2 \psi} - \cos{\theta} \sin{2 \phi} \sin{ 2 \psi}$, and
$F_{\times} = \frac{1}{2} (1 + \cos^2{\theta}) \sin{2\phi} \cos{2 \psi} + \cos{\theta} \sin{2 \phi} \cos{ 2 \psi}$ are so-called antenna patterns. The four angles ($\theta, \phi, \psi, \iota$) describe respectively the
direction to the BBH system relative to the detector and the binary orientation relative to the line of sight between it and the detector. 
They are independent and one can assume that $(\cos\theta, \phi/\pi, \psi/\pi, \cos\iota)$ distributed uniformly over the range $[-1, 1]$. The GW signal is considered as detectable if its \snr\ is over the detecting threshold, i.e., $\rho > \rho_0 = 8$.

\subsection{Monte Carlo Approach} \label{MC}

Our aim is to build up a sufficient volume of BBH systems in the mock universe by randomly generating the key parameters for each BBH system. We sample them according to the yearly merging rate in a redshift interval  $[z_{s}, z_{s}+dz_{s}]$:
 \begin{equation}
 d\dot{N} (z_s)=4\pi\left(\frac{c}{H_{0}}\right)^3\frac{\dot{n}_{0}(z_{s})}{1+z_{s}}\frac{\tilde{r}^2(z_{s})}{E(z_{s})}dz_{s}. 
 \end{equation}
where the intrinsic BBH merger rate $\dot{n}_{0}(z_{s})$ is the one predicted by the population synthesis model (using {\tt StarTrack} code\footnote{The data is taken from the website \url{http://www.syntheticuniverse.org}.}) in \citet{Dominik13}, $\tilde{r}(z_{s})$ is the dimensionless comoving distance to the source, and $E (z_s)$ is
the dimensionless expansion rate of the universe at redshift $z_s$. 
Concerning the cosmological model, in order to comply with \citet{Dominik13} we assume a flat $Lambda$CDM\kai{L} model with $\Omega_m = 0.3$ and $H_0 = 70 \; km s^{-1} Mpc^{-1}$\kai{no need to repeat here?}.
%Hence, the overall amount of BBH events in the universe can be calculated by ${\dot N} = \int_0^{ \infty} \frac{d {\dot N (z)}}{dz} dz$.
For each BBH system, we sample the probability distribution of the key parameters to randomly generate their values. These key parameters include the four angles $(\theta, \phi, \psi, \iota)$ in the Equation~(\ref{Theta})  and the masses of each BH in the binary system (i.e., \mone\ and \mtwo).
For the purpose of randomly generating the BH masses, we follow the previous works \citep{Kovetz2017PhRvD, Abbott2018b, Fishbach2018} and assume that \mone\ follows a power law distribution with a hard cut at both maximum and minimum mass:
 \begin{equation} \label{equ_powlaw}
p(m_1|\alpha, M_{max}, M_{min}) = m_1^{\alpha} \mathcal{H}(m_1-M_{min}) \mathcal{H}(M_{max}-m_1),
 \end{equation}
where $\mathcal{H}$ is the Heaviside step function\kai{We may express this function here}. Then, the secondary mass, \mtwo, is fixed as uniform between $[M_{min}, m_1]$. Let us note that, we only take the \mone\ to reconstruct the BHMF, thus the assumption of the distribution for \mtwo\ actually does not affect the inference for the shape of BHMF. These parameters determine the value of $\Theta$ and ${\cal M}_0$ in Equation~(\ref{SNR}). We combine them with their redshift $z_s$ to generate the $\rho$ of each BBH system. We collect only the events which have $\rho > \rho_0 = 8$, meaning that those events with $\rho < 8$ are to\kai{too} faint to be detected\kai{to detect}. 

Concerning the BHMF we consider two scenarios. In the first scenario, the $\alpha$ exponent\kai{exponent $\alpha$} is constant, hence the shape of the BHMF is fixed throughout the redshfit range probed by the ET. In the second scenario, we consider that $\alpha$ varies as a function of redshift according to:
 \begin{equation} \label{equ_alphaz}
\alpha(z) = \alpha_0 + \alpha_1\frac{z}{1+z} , 
 \end{equation}
 \kai{From my view, I would parameterize $M_{max}$ and $M_{min}$ rather than the shape of mass function, it is like the CDM hieratical model.
 BH mass grows with time maybe?}
so that the $\alpha(z)$ would transform gradually from $\alpha_0$ to $\alpha_0+\alpha_1$ through low$-z$ to high$-z$. This is actually the first order Taylor expansion in the scale factor $a(t)$ of an unknown $\alpha(a(t))$\kai{it's redundant} function.



\subsection{Measurement Error\kai{parameter estimation error}} \label{sec_noiselevel}
We aim to produce the mock dataset of the future GW events representative of the ET  measurements. In order to consider the measurement uncertainties in a realistic way, we inject\kai{distribute} random statistical uncertainties into the mock data\kai``{mock data" has included the uncertainties?} as described below.

The parameters measureable from the BBH inspiral waveform comprise \dl, chirp mass and $\rho$. Individual masses \mone\ and \mtwo\ are derived from the combination of the chirp mass and the total mass \mone+\mtwo, which can also be extracted from the chirp waveform. As a recipe to set up the noise levels of our simulated data we adopt the results of \citet{Ghosh2016}, who  explored the expected statistical uncertainties with which the parameters of black hole binaries can be measured from GW observations by next generation ground-based GW observatories. 
Moreover, we stress that the measurements of the BBH parameters are characterized by ${\it skewed}$ distributions. Therefore, instead of the traditional Gaussian distribution, we assume that the measured parameters follow the Log-Normal distribution\kai{cite references} with the standard deviation of  ${\cal M}_0$, \dl, and \mone\ equal to 0.17, 0.35 and 0.2, respectively. For instance, if the $m_{1,fid}$ is the true value for \mone, its probability density is:
 \begin{equation} \label{equ_lognorm}
p(m_1) = \frac{1}{m_1 \sigma_{m_1} \sqrt{2\pi}} exp \big(- \frac{log(m_1)-log(m_{1,fid})}{2\sigma_{m_1}} \big) \kai{you may use \left[ \right]}
 \end{equation}
 

Having clarified the MC approach and defined data the uncertainty level, we are capable of producing the mock GW dataset. As an illustration, we list in Table~\ref{tab_GW_mock_data} a 
part of the simulated data comprising in total \kai{one?} thousand BBH inspiral events. 
We use these data to infer the BHMF in next sections. \kai{In my understandings, as a prediction paper, only the uncertainties matter. The best-fit values must be deviated from the inputs for one MC process and are meaningless.}

\begin{deluxetable}{lcccc}
\tablecolumns{5}
\tabletypesize{\footnotesize}
\tablewidth{0pt}
\tablecaption{Illustration of the mock GW catalog} 
\tablehead{ 
\colhead{Object ID} &
\colhead{\mone}&
\colhead{Luminosity Distance} & 
\colhead{Chirp Mass} &
\colhead{SNR}
\\ 
\colhead{} &
\colhead{($M_\odot$)}&
\colhead{(Mpc)} & 
\colhead{($M_\odot$)} &
\colhead{(\snr)}
\\
\colhead{(1)} &
\colhead{(2)} &
\colhead{(3)} &
\colhead{(4)} &
\colhead{(5)}
} 
\startdata
%\multicolumn{5}{c}{Sample presented in \citet{Treu+07}}\\
%\\
ID1 & $95.85\substack{+21.22\\-17.37}$  & $87120.7\substack{+19288.8\\-15792.3}$  & $61.87\substack{+13.70\\-11.21}$ & 28.707 \\
ID2 & $13.31\substack{+2.95\\-2.41}$  & $81476.5\substack{+18039.1\\-14769.2}$  & $11.68\substack{+2.59\\-2.12}$ & 10.468 \\
ID3 & $7.40\substack{+1.64\\-1.34}$  & $7456.8\substack{+1651.0\\-1351.7}$  & $6.82\substack{+1.51\\-1.24}$ & 39.673 \\
ID4 & $19.02\substack{+4.21\\-3.45}$  & $96201.9\substack{+21299.4\\-17438.4}$  & $19.11\substack{+4.23\\-3.46}$ & 12.227 \\
ID5 & $15.12\substack{+3.35\\-2.74}$  & $47645.3\substack{+10548.8\\-8636.6}$  & $14.24\substack{+3.15\\-2.58}$ & 12.672 \\
ID6 & $18.95\substack{+4.20\\-3.43}$  & $23937.4\substack{+5299.8\\-4339.1}$  & $13.86\substack{+3.07\\-2.51}$ & 16.027 \\
ID7 & $8.65\substack{+1.92\\-1.57}$  & $44053.0\substack{+9753.4\\-7985.4}$  & $6.99\substack{+1.55\\-1.27}$ & 8.383 \\
ID8 & $40.03\substack{+8.86\\-7.26}$  & $60432.5\substack{+13379.9\\-10954.6}$  & $25.53\substack{+5.65\\-4.63}$ & 17.917 \\
ID9 & $32.58\substack{+7.21\\-5.91}$  & $4293.5\substack{+950.6\\-778.3}$  & $18.58\substack{+4.11\\-3.37}$ & 34.190 \\
ID10 & $9.88\substack{+2.19\\-1.79}$  & $50294.8\substack{+11135.4\\-9116.9}$  & $4.65\substack{+1.03\\-0.84}$ & 9.608 \\
... & $...$ & ... & ... & ...\\
ID991 & $7.90\substack{+1.75\\-1.43}$  & $10175.7\substack{+2252.9\\-1844.5}$  & $7.31\substack{+1.62\\-1.32}$ & 9.354 \\
ID992 & $15.48\substack{+3.43\\-2.81}$  & $8058.1\substack{+1784.1\\-1460.7}$  & $17.14\substack{+3.80\\-3.11}$ & 11.149 \\
ID993 & $6.11\substack{+1.35\\-1.11}$  & $9566.9\substack{+2118.1\\-1734.2}$  & $4.11\substack{+0.91\\-0.75}$ & 10.703 \\
ID994 & $17.41\substack{+3.85\\-3.16}$  & $232095.1\substack{+51386.5\\-42071.7}$  & $14.46\substack{+3.20\\-2.62}$ & 8.444 \\
ID995 & $23.76\substack{+5.26\\-4.31}$  & $127615.4\substack{+28254.4\\-23132.7}$  & $16.97\substack{+3.76\\-3.08}$ & 14.972 \\
ID996 & $10.43\substack{+2.31\\-1.89}$  & $65546.6\substack{+14512.2\\-11881.6}$  & $6.96\substack{+1.54\\-1.26}$ & 9.497 \\
ID997 & $5.79\substack{+1.28\\-1.05}$  & $24315.0\substack{+5383.4\\-4407.6}$  & $6.93\substack{+1.53\\-1.26}$ & 14.177 \\
ID998 & $12.48\substack{+2.76\\-2.26}$  & $98731.2\substack{+21859.3\\-17896.9}$  & $6.85\substack{+1.52\\-1.24}$ & 13.340 \\
ID999 & $6.95\substack{+1.54\\-1.26}$  & $75187.9\substack{+16646.8\\-13629.2}$  & $3.40\substack{+0.75\\-0.62}$ & 9.437 \\
ID1000 & $6.53\substack{+1.45\\-1.18}$  & $27801.3\substack{+6155.3\\-5039.5}$  & $9.79\substack{+2.17\\-1.77}$ & 8.390 \\
%... & $...$ & ... & ... \\
\enddata
\label{tab_GW_mock_data}
\tablecomments{The catalog of simulated thousand BBH inspiral events is used to test the inference of the BHMF from the data attainable in forthcoming next generation GW detector -- the ET. \kai{What do the numbers mean? Are they 50th plus 16th and 84th pencentiles?}
}
\end{deluxetable}

\vspace{1cm}
\section{Theoretical Framework}  \label{sec_theory}
In this section, we describe the fitting procedure for the parameterized BHMFs. 
In principle, the modeling for a dataset which follows a power-law distribution as Equation~(\ref{equ_powlaw}) is very straightforward. To derive the posterior of the parameters, one only needs to combine all the measured values together in a joint likelihood:
 \begin{equation} \label{equ_lik_powlaw}
 P(\alpha, M_{max}, M_{min}|m_{1}) \propto  \prod_{i=1}^{total} P(m_{1,i}|\alpha, M_{max}, M_{min}).
 \end{equation}
However, the simulated values of \mone\ shown in Table~\ref{tab_GW_mock_data} actually deviate from the initial power-law distribution. This deviation stems from several effects that exist in reality. In Section~\ref{sec_likelihood_noise} and \ref{sec_likelihood_sf}, we introduce them and explore the ways to account for them.

\subsection{Measurement Uncertainty}\label{sec_likelihood_noise}
The intrinsic \mone\ follows a power-law distribution, however the measured  \mone\ are affected by Log-Normal distribution and thus they do not follow a power-law function anymore \citep{Koen2009}. In theory, if the event $X$ follows a power-law distribution and its observed values are subject to the Gaussian uncertainty, then $X + e$ is distributed according to the convolution of the power-law and Gaussian distributions. Likewise, given that the noised data follow the Log-Normal distribution, the intrinsic power-law should be convolved with it and enter the likelihood as:
 \begin{equation} \label{equ_lik_conv}
 P(\alpha, M_{max}, M_{min}) \propto  \prod_{i=1}^{total} \hat{P}(m_{1,i}|\alpha, M_{max}, M_{min}),
 \end{equation}
where the $\hat{P}$ is the initial power-law function convolved with the Log-Normal distribution using the standard deviation as 0.2 as we assumed. We illustrate the effect of such convolution in the Figure~\ref{fig:result_slope}.

\begin{figure}%[!b]
\includegraphics[width=1.05\linewidth]{convolving.pdf}
\caption{
Figure illustrating the convolution of a power-law distribution with a Log-Normal distribution having $\sigma = 0.2$. One can see that the convolution make distribution shallower, smoothes the breaking edge at $m_1 = 5 M_{\odot}$ and makes the slope less steep.
}
\label{fig:result_slope}
\end{figure}

\subsection{Selection Effect}\label{sec_likelihood_sf}
The GW observations have a tendency to discover more significant events, known as Malmquist bias. The GW systems with higher values \mone\ produce  stronger signals and thus have a higher probability to be detected. If this effect is not taken into account, the final BHMFs would be biased to the high mass end.

To overcome this selection effect, we introduce the selection factor $\eta$ for the GW event, which is the detecting probability of one event in a repeated simulation. The meaning of this factor $\eta$ is straightforward -- if one GW event has $\eta=0.2$ it means that this event has 80\% probability of being be missed. In other words, four equivalent events would have been missed. Thus, for this event, one needs to re-calibrate its influence by  enhancing the likelihood by a power of 5. Hence, to account for this  selection effect, we modify the likelihood as:
 \begin{equation} \label{equ_lik_sf}
 P(\alpha, M_{max}, M_{min}) \propto  \prod_{i=1}^{total} \hat{P}(m_{1,i}|\alpha, M_{max}, M_{min})^{1/\eta},
 \end{equation}
where $\eta$ is directly determined by the probability distribution of $\rho$, i.e. $\eta = P(\rho>8)$. In order to use the Equation~(\ref{SNR}), the distribution function of $\Theta$ is known from the MC simulations, the \cmass\ and \dl\ are provided in the mock dataset as demonstrated in Table~\ref{tab_GW_mock_data}. Yet, the redshift $z_s$ is the unknown parameter since it is non-measurable in the GW detectors. Therefore, we take the \dl\ as redshift estimator\kai{so $z_s$ also has an uncertainty?}.
Note that the \dl\ and \cmass\ both have asymmetric distributions with large scatter,hence the inferred $\eta$ is distributed around its true value in a skewed way. We find\kai{prove it?} that this skewness could be well described by a Log-Normal distribution, with multiplicative standard deviation\footnote{In Log-Normal distribution, the multiplicative standard deviation is the exponent  of the standard deviation, i.e., $\sigma^* = exp(\sigma)$.} as $\sigma^*=log(\eta)/3$. Thus, we manually correct this skewness and obtain the non-biased $\eta$.

\subsection{Luminosity Distance as Redshift Estimator} 
\label{sec_dl_z}
%The redshift is not detectable by GW, however, can be inferred from the DL. 
In the previous section, we take \dl\ as the redshift estimator to derive the redshift and hence selection factor $\eta$. The way to derive the $z$ is quite straightforward: simply an inverse solution of integral function when knowing the \dl$(z)$ and fixing the cosmological model\kai{$d_L$ has an uncertainty, so does $z_s$?}.

Therefore, once the cosmological model is assumed, indirect inference of $z_s$ creates an opportunity to model the BHMF slope as a function of redshift. Therefore, we are able to investigate the second scenario described by the Equation~(\ref{equ_alphaz}) as:
 \begin{equation} \label{equ_lik_alphaz}
 \begin{split}
 P&(\alpha_0, \alpha_1, M_{max}, M_{min}) \propto \\
  &\prod_{i=1}^{total} \hat{P}(m_{1i}, z_{inf,i} |\alpha_0, \alpha_1, M_{max}, M_{min})^{1/\eta}.
  \end{split}
 \end{equation}
 
 We present our inference for the BHMF using the mock data in the next section. 


\vspace{1cm}
\section{Result}\label{sec_result}
%We present the result in this section.
%One thousand of data points.
%An appendix to introduce the correction for the skewness for the $\eta$.
We fit the mock data to the BHMF model to infer the distribution of the best-fitted parameter \kai{distributions, parameters?}. To infer a non-biased distribution, we adopt the realization approach. The details of the simulation are the following. In each realization, we simulate a thousand of BBH inspiral GW events and infer the best-fit parameters using minimization of the chi-square objective function. 
\textbf{The realization is completed when the inferred best-fit parameters converged.} 

In the first scenario, we consider the slope $\alpha$ as a constant. We generated the mock data by taking $\alpha~=~2.35$, $M_{min}~=~5M_{\odot}$, $M_{max}~=~80M_{\odot}$ as the fiducial values\kai{Why these values?}. We calculate the likelihood by Equation~(\ref{equ_lik_sf}) to infer the best-fitted parameters in each realization. In Figure~\ref{fig_result_a}, we present the posterior distribution of the inferred parameters. We find that the non-biased results have the  best-fitted parameters distributed as $\alpha = 2.36\substack{+0.09\\-0.08}$, $M_{max} = 80.54\substack{+5.45\\-5.60}$,  $M_{min} = 5.03\substack{+0.17\\-0.15}$. Our inference of $\alpha$ indicates that a thousand of GW events could constrain the slope within $3.5\%$ level.

\begin{figure}%[!b]
\includegraphics[width=1.0\linewidth]{fig_results_3para.pdf}
\caption{
One- and two-dimensional distributions for the best-fitted parameters in the scenario A. The BHMF is assumed as a power-law with hard cut at the $M_{min}$ and $M_{max}$, with a constant slope ($\alpha$) across all the redshifts.\kai{Is $M_{max}$ determined by the observation? I mean, from
the observed largest mass? Is it necessary a parameter in your model?}
}
\label{fig_result_a}
\end{figure}

In the second scenario, the $\alpha$ evolves with redshift according to the Equation~(\ref{equ_alphaz}). We assume the fiducial parameters as $\alpha_0~=~2.35$, $\alpha_1~=~0.75$, $M_{min}~=~5M_{\odot}$, $M_{max}~=~80M_{\odot}$\kai{Why these values?} to generate a thousand datasets in each realization. We present the results in Figure~\ref{fig_result_b}. Since the second scenario has one more parameter, distributions of the best-fitted parameters have larger scatter and can be summarized as $\alpha_0 = 2.32\substack{+0.35\\-0.36}$, $\alpha_1 = 0.73\substack{+0.52\\-0.50}$, $M_{max} = 78.03\substack{+10.03\\-8.40}$ and  $M_{min} = 5.02\substack{+0.14\\-0.14}$. Not surprisingly, the degeneracy exsits between the $\alpha_0$ and $\alpha_1$. 

We highlight that in this scenario, it is the inferred uncertainty of $\alpha_1$ that matters the most. Our result show that, with a volume of one thousands GW measurements, the inferred value of $\alpha_1$ would have a precision of $\pm0.5$. That is to say, this volume of measurements is able to distinguish the evolution of BHMF, when $\alpha_1$ is deviated from 0 by a value of 0.5\kai{only in one sigma confidence interval?}. Limited by the computing power, we haven't tested the larger sample of measurements. However, conjecturing that the precision of inference is increasing with the sample size as a function of $\sqrt{N}$, one year measurements of ET ($\sim10^5$ in total) would result in the $\alpha_1$ inferred with the precision down to $\sim0.05$.
We also note that the distribution of the best-fitted parameters ($\alpha_0$, $\alpha_1$) does not follow the Gaussian distribution, but rather a large fraction of it is concentrated at the center. 
%As a result, the 1-$\sigma$ confidence interval in 2-D parameter space are narrower than the ones in 1-D space. %\textcolor{blue}{(What does this suggest?)} 

\begin{figure}%[!b]
\includegraphics[width=1.0\linewidth]{fig_results_4para.pdf}
\caption{
The same as Figure~\ref{fig_result_a} but for the scenario B, where the $\alpha$ of BHMF is evolving with redshift as $\alpha(z) = \alpha_0 + \alpha_1\frac{z}{1+z}$. 
}
\label{fig_result_b}
\end{figure}

\vspace{1cm}
\section{Conclusion \& Discussion} \label{sec_summary}
\kai{Can you discuss what if the distribution is not power-law? Can your method test this model?}
The third-generation gravitational wave detector, the Einstein Telescope, will \kai{be} very powerful and capable of detecting $\sim10^5$ GW events per year, with redshift up to $z\sim17$. In this study, we investigated how the detections of the BBHs \kai{remove ``s"} mergers could improve our knowledge of the black hole mass function.

We performed the Monte Carlo simulation to generate the mock measurements of GW signals\kai{parameters inferred from GW signals} from BBHs that would be detected by ET. As a starting point, we assumed that the BHMF for the primary BH mass followed a power law distribution. Based on the BBH intrinsic merger rate predicted by {\tt StarTrack}, we randomly simulated the key parameters of the BBH systems, including the chirp masses, redshifts and orientation factors and calculated  their corresponding signal-to-noise ratio \snr\ for the ET. We collected the events whose \snr\ exceeds the detecting threshold and injected Log-Normal noise to the detected parameter, including BH mass, chirp mass, luminosity distance to simulate the mock data.


We built up a theoretical framework and explore to use the mock measurements to infer the BHMF. We took into account the measurement uncertainties and the selection effect which would bias the inference. We used the realization approach, one thousand GW events per realization, and estimated the distribution of the best-fitted parameters of the BHMF, including the power law slope $\alpha$, the maximum BH mass $M_{max}$ and the minimum BH mass $M_{min}$. Furthermore, we used the luminosity distance as redshift estimator and tested whether one can infer the $\alpha$ as a function of redshift. We summarize our main results as follows:
\begin{enumerate}
\item Assuming the $\alpha$ is constant in redshift, one could infer the $\alpha$, $M_{max}$ and $M_{min}$ precisely and accurately. With one thousand measurements of BBHs events, the $\alpha$ would reach 3\% level, 
%i.e., Figure~\ref{fig_result_a}.
\item Testing the scenario that $\alpha$ is evolving with redshift as $\alpha(z) = \alpha_0 + \alpha_1\frac{z}{1+z}$, our results show that a volume of one thousand measurements of BBHs events would provide the evolving parameter $\alpha_1$ with an uncertainty level of $\pm0.5$. Meaning that with this sample size one is able to recognize the evolution of BHMF when $\alpha_1$ deviates from $0$ by $0.5$.
\item According to the fact that the precision of the inference increases with the sample size, as a function of $\sqrt{N}$, we conclude that one year BBH sample by ET would be able to deliver the value of $\alpha_1$ with precision down to 0.05.
\end{enumerate}

We point out a few limitations of this work. First, we have adopted a template of intrinsic BBH merger rate based on the predictions by a standard model in {\tt StarTrack}, which can be different from the realistic one. Of course, the intrinsic BBH merger rate is unknown yet, which is related to 
lack of detailed knowledge of different elements such as BBH masses, explosion mechanism, the metallicity history and the time delay distribution. Also, for the sake of simplicity, we simulated the value of the secondary BH mass \mtwo\ by assuming that two masses of BBHs have independent distributions, which probably is not exactly true. However, one can expect that these limitations would more strongly affect the prediction of the yearly detection rate of the GW events and their redshift distribution. Using a sample with the same volume but different redshift distribution, the inference on the BHMF parameters could be very similar. 

In this work, we focused on the inference of the BHMF using the mass properties by the BBH. However, it is worth to note that our approach could be used to address other problems. For example, one could infer the spin of BH \citep{Abbott2018b}, the mass function for the binary of NS-NS, NS-BH system, though these events are detectable at lower redshift ($z<4$). In addition, using the luminosity as redshift estimator, one should also be able to reconstruct the BBH intrinsic merger rate \citep{Fishbach2018}. 
, the cosmological parameter.


\acknowledgments
We thank Hosek Jr., M.W for the useful discussion.

This work was supported by the National Natural Science Foundation of China under grant Nos. 11633001 and 11373014, the Strategic Priority Research Program of the Chinese Academy of Sciences, grant No. XDB23000000, and the Interdiscipline Research Funds of Beijing Normal University.

X. Ding acknowledges support by China Postdoctoral Science Foundation Funded Project (No. 2017M622501).
%L. Yang is supported from the China Scholarship Council. 
M.B. was supported by the Key Foreign Expert Program for the Central Universities No. X2018002.
K. Liao was supported by the National Natural Science Foundation of China (NSFC) No. 11603015.
\software{  {\sc corner}, \citep{corner},
        Matplotlib \citep{Matplotlib},
        and standard Python libraries.
        }

\bibliography{reference}
%\input{reference.bbl}

%\newpage
%\appendix
%\section{section}\label{appendix_section}
%TEXTTEXTTEXTTEXTTEXTTEXTTEXTTEXTTEXT
%\newpage

%\newpage
%\appendix
%\section{Correction for the skewness of the selection factor}\label{appA}
%1. Describe the bias of the selection.
%2. The correction by $\eta/3.$


\end{document}
